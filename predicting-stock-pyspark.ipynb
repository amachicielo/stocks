{"cells":[{"source":"<a href=\"https://www.kaggle.com/code/youlikecode/predicting-stock-pyspark?scriptVersionId=122713433\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown","outputs":[],"execution_count":0},{"cell_type":"markdown","id":"e58a92ea","metadata":{"papermill":{"duration":0.005057,"end_time":"2023-03-20T01:46:29.007156","exception":false,"start_time":"2023-03-20T01:46:29.002099","status":"completed"},"tags":[]},"source":["# Problem definition"]},{"cell_type":"markdown","id":"e6672d25","metadata":{"papermill":{"duration":0.003456,"end_time":"2023-03-20T01:46:29.014737","exception":false,"start_time":"2023-03-20T01:46:29.011281","status":"completed"},"tags":[]},"source":["In this project, we’ll learn how to predict stock prices using python, pandas, and scikit-learn. \n","we’ll create a machine learning model, and develop a back-testing engine. \n","\n","In this case, let’s say that we are trading stocks. We’re interested in making profitable stock trades with minimal risk. So when we buy a stock, we want to be fairly certain that the price will increase. We’ll buy stock when the market opens, and sell it when the market closes."]},{"cell_type":"code","execution_count":1,"id":"8f42cc06","metadata":{"execution":{"iopub.execute_input":"2023-03-20T01:46:29.024086Z","iopub.status.busy":"2023-03-20T01:46:29.023691Z","iopub.status.idle":"2023-03-20T01:47:16.792237Z","shell.execute_reply":"2023-03-20T01:47:16.790697Z"},"papermill":{"duration":47.776827,"end_time":"2023-03-20T01:47:16.795235","exception":false,"start_time":"2023-03-20T01:46:29.018408","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting pyspark\r\n","  Downloading pyspark-3.3.2.tar.gz (281.4 MB)\r\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m281.4/281.4 MB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l-\b \bdone\r\n","\u001b[?25hCollecting py4j==0.10.9.5\r\n","  Downloading py4j-0.10.9.5-py2.py3-none-any.whl (199 kB)\r\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.7/199.7 kB\u001b[0m \u001b[31m14.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n","\u001b[?25hBuilding wheels for collected packages: pyspark\r\n","  Building wheel for pyspark (setup.py) ... \u001b[?25l-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \bdone\r\n","\u001b[?25h  Created wheel for pyspark: filename=pyspark-3.3.2-py2.py3-none-any.whl size=281824025 sha256=078ad133437cec12349f6957d3c84b6a1f34a9a8d40826130887bc7074fab20a\r\n","  Stored in directory: /root/.cache/pip/wheels/5a/54/9b/a89cac960efb57c4c35d41cc7c9f7b80daa21108bc376339b7\r\n","Successfully built pyspark\r\n","Installing collected packages: py4j, pyspark\r\n","  Attempting uninstall: py4j\r\n","    Found existing installation: py4j 0.10.9.7\r\n","    Uninstalling py4j-0.10.9.7:\r\n","      Successfully uninstalled py4j-0.10.9.7\r\n","Successfully installed py4j-0.10.9.5 pyspark-3.3.2\r\n","\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\r\n","\u001b[0m"]}],"source":["!pip install pyspark"]},{"cell_type":"code","execution_count":2,"id":"03e26c8e","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2023-03-20T01:47:16.820183Z","iopub.status.busy":"2023-03-20T01:47:16.819758Z","iopub.status.idle":"2023-03-20T01:47:17.172071Z","shell.execute_reply":"2023-03-20T01:47:17.171118Z"},"papermill":{"duration":0.368269,"end_time":"2023-03-20T01:47:17.174815","exception":false,"start_time":"2023-03-20T01:47:16.806546","status":"completed"},"tags":[]},"outputs":[],"source":["# Loading the packages\n","from pyspark.sql import SparkSession\n","from pyspark.ml.regression import LinearRegression\n","from pyspark.ml.feature import VectorAssembler\n","from pyspark.ml.evaluation import RegressionEvaluator"]},{"cell_type":"code","execution_count":3,"id":"2227a1f3","metadata":{"execution":{"iopub.execute_input":"2023-03-20T01:47:17.199579Z","iopub.status.busy":"2023-03-20T01:47:17.19842Z","iopub.status.idle":"2023-03-20T01:47:22.949477Z","shell.execute_reply":"2023-03-20T01:47:22.947827Z"},"papermill":{"duration":5.767402,"end_time":"2023-03-20T01:47:22.953282","exception":false,"start_time":"2023-03-20T01:47:17.18588","status":"completed"},"tags":[]},"outputs":[{"name":"stderr","output_type":"stream","text":["Setting default log level to \"WARN\".\n","To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"]},{"name":"stdout","output_type":"stream","text":["23/03/20 01:47:20 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"]}],"source":["# Create an instance of your Spark session\n","spark = SparkSession.builder.appName('stock_price_prediction').getOrCreate()"]},{"cell_type":"code","execution_count":4,"id":"1f1eefaf","metadata":{"execution":{"iopub.execute_input":"2023-03-20T01:47:22.987255Z","iopub.status.busy":"2023-03-20T01:47:22.986388Z","iopub.status.idle":"2023-03-20T01:48:02.419072Z","shell.execute_reply":"2023-03-20T01:48:02.417744Z"},"papermill":{"duration":39.452332,"end_time":"2023-03-20T01:48:02.422753","exception":false,"start_time":"2023-03-20T01:47:22.970421","status":"completed"},"tags":[]},"outputs":[{"name":"stderr","output_type":"stream","text":["                                                                                \r"]}],"source":["# Load the data from the csv file\n","path = \"/kaggle/input/daily-historical-stock-prices-1970-2018/historical_stock_prices.csv\"\n","df = spark.read.csv(path, header=True, inferSchema=True)\n","df = df.withColumn('date', df['date'].cast('timestamp'))"]},{"cell_type":"code","execution_count":5,"id":"b2668ee1","metadata":{"execution":{"iopub.execute_input":"2023-03-20T01:48:02.450804Z","iopub.status.busy":"2023-03-20T01:48:02.450252Z","iopub.status.idle":"2023-03-20T01:48:02.618265Z","shell.execute_reply":"2023-03-20T01:48:02.616946Z"},"papermill":{"duration":0.185239,"end_time":"2023-03-20T01:48:02.622184","exception":false,"start_time":"2023-03-20T01:48:02.436945","status":"completed"},"tags":[]},"outputs":[],"source":["# Pre-process the data\n","data = df.select('open', 'close', 'low', 'high', 'volume').na.drop()\n","data = data.select(*(data[c].cast(\"float\").alias(c) for c in data.columns))"]},{"cell_type":"code","execution_count":6,"id":"0c932c97","metadata":{"execution":{"iopub.execute_input":"2023-03-20T01:48:02.660161Z","iopub.status.busy":"2023-03-20T01:48:02.659638Z","iopub.status.idle":"2023-03-20T01:48:02.700679Z","shell.execute_reply":"2023-03-20T01:48:02.699384Z"},"papermill":{"duration":0.064556,"end_time":"2023-03-20T01:48:02.704175","exception":false,"start_time":"2023-03-20T01:48:02.639619","status":"completed"},"tags":[]},"outputs":[],"source":["# Split the data into a training set and a test set\n","(trainingData, testData) = data.randomSplit([0.7, 0.3], seed=42)"]},{"cell_type":"code","execution_count":7,"id":"ba240bcd","metadata":{"execution":{"iopub.execute_input":"2023-03-20T01:48:02.742051Z","iopub.status.busy":"2023-03-20T01:48:02.741152Z","iopub.status.idle":"2023-03-20T01:48:03.051355Z","shell.execute_reply":"2023-03-20T01:48:03.049907Z"},"papermill":{"duration":0.333201,"end_time":"2023-03-20T01:48:03.054968","exception":false,"start_time":"2023-03-20T01:48:02.721767","status":"completed"},"tags":[]},"outputs":[],"source":["# Define the characteristics and the target variable\n","assembler = VectorAssembler(inputCols=['open', 'low', 'high', 'volume'], outputCol='features')\n","trainingData = assembler.transform(trainingData)\n","testData = assembler.transform(testData)\n","trainingData = trainingData.select(\"features\", \"close\")\n","testData = testData.select(\"features\", \"close\")"]},{"cell_type":"code","execution_count":8,"id":"2bf49a4f","metadata":{"execution":{"iopub.execute_input":"2023-03-20T01:48:03.09237Z","iopub.status.busy":"2023-03-20T01:48:03.091954Z","iopub.status.idle":"2023-03-20T01:48:03.151809Z","shell.execute_reply":"2023-03-20T01:48:03.15031Z"},"papermill":{"duration":0.082976,"end_time":"2023-03-20T01:48:03.155857","exception":false,"start_time":"2023-03-20T01:48:03.072881","status":"completed"},"tags":[]},"outputs":[],"source":["# Create the model using PySpark's linear regression algorithm\n","lr = LinearRegression(labelCol=\"close\", featuresCol=\"features\", regParam=0.1)"]},{"cell_type":"code","execution_count":9,"id":"6974c160","metadata":{"execution":{"iopub.execute_input":"2023-03-20T01:48:03.193989Z","iopub.status.busy":"2023-03-20T01:48:03.193456Z","iopub.status.idle":"2023-03-20T01:49:56.698835Z","shell.execute_reply":"2023-03-20T01:49:56.697272Z"},"papermill":{"duration":113.528837,"end_time":"2023-03-20T01:49:56.702638","exception":false,"start_time":"2023-03-20T01:48:03.173801","status":"completed"},"tags":[]},"outputs":[{"name":"stderr","output_type":"stream","text":["                                                                                \r"]}],"source":["# Train the model using the training set\n","lrModel = lr.fit(trainingData)"]},{"cell_type":"code","execution_count":10,"id":"85614bd9","metadata":{"execution":{"iopub.execute_input":"2023-03-20T01:49:56.745687Z","iopub.status.busy":"2023-03-20T01:49:56.744979Z","iopub.status.idle":"2023-03-20T01:49:56.823358Z","shell.execute_reply":"2023-03-20T01:49:56.82195Z"},"papermill":{"duration":0.103999,"end_time":"2023-03-20T01:49:56.827033","exception":false,"start_time":"2023-03-20T01:49:56.723034","status":"completed"},"tags":[]},"outputs":[],"source":["# Perform the prediction using the test suite\n","predictions = lrModel.transform(testData)"]},{"cell_type":"code","execution_count":11,"id":"9c1a719d","metadata":{"execution":{"iopub.execute_input":"2023-03-20T01:49:56.858888Z","iopub.status.busy":"2023-03-20T01:49:56.858491Z","iopub.status.idle":"2023-03-20T01:51:30.272948Z","shell.execute_reply":"2023-03-20T01:51:30.271559Z"},"papermill":{"duration":93.432923,"end_time":"2023-03-20T01:51:30.276729","exception":false,"start_time":"2023-03-20T01:49:56.843806","status":"completed"},"tags":[]},"outputs":[{"name":"stderr","output_type":"stream","text":["[Stage 8:=====================================================>   (14 + 1) / 15]\r"]},{"name":"stdout","output_type":"stream","text":["MSE: 7611.022790527066\n","R2: 0.9990251050868884\n"]},{"name":"stderr","output_type":"stream","text":["                                                                                \r"]}],"source":["# Evaluate the model using evaluation metrics\n","\n","# mean square error\n","evaluator = RegressionEvaluator(labelCol=\"close\", predictionCol=\"prediction\", metricName=\"mse\")\n","mse = evaluator.evaluate(predictions)\n","\n","# coefficient of determination\n","evaluator = RegressionEvaluator(labelCol=\"close\", predictionCol=\"prediction\", metricName=\"r2\")\n","r2 = evaluator.evaluate(predictions)\n","\n","print('MSE:', mse)\n","print('R2:', r2)"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.12"},"papermill":{"default_parameters":{},"duration":314.844528,"end_time":"2023-03-20T01:51:32.924276","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2023-03-20T01:46:18.079748","version":"2.4.0"}},"nbformat":4,"nbformat_minor":5}